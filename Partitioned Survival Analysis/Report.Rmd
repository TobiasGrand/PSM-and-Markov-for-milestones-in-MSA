---
title: "Partitioned Survival Model and Markov Model comparison for Multiple System Atrophy "
author: "Tobias Sydendal Grand"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 3
    toc_float: true
    number_sections: yes
    theme: united
    highlight: tango
    code_folding: hide
editor_options: 
  chunk_output_type: console
execute:
  collapse: true
---

Please see code in collapsed sections above output by pressing "Show".

# Data Analysis

## Data Preparation

In below code chunk we set the working directory and load packages required for the analysis.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Set working directory
setwd("C:/Users/TOGN/OneDrive - H. Lundbeck A S/University of Sheffield/Part III Partitioned Survival Modelling/Copy of R project/Partitioned Survival Analysis/Partitioned Survival Analysis")

# Check if the working directory exists
if (!file.exists("C:/Users/TOGN/OneDrive - H. Lundbeck A S/University of Sheffield/Part III Partitioned Survival Modelling/Copy of R project/Partitioned Survival Analysis/Partitioned Survival Analysis")) {
  stop("The specified working directory does not exist.")
}

# Load packages
packages <- c("IPDfromKM", "tidyverse", "png", "data.table", "hesim", "gridExtra", "grid", "ggplot2", "survival", "knitr", "kableExtra", "flexsurv", "msm", "dplyr", "tidyr", "MCMCpack")

# Install and load packages
for (pkg in packages) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}


opts_chunk$set(echo = TRUE)

```

### Code example (aid-required walking) to manually digitise Kaplan-Meier curves

A separate R file DigitiseKaplanMeier.R in folder named data contains code to generate digitised Kaplan-Meier curves from:

``` 
Watanabe et al 2022 Progression and prognosis in multiple system atrophy (DOI: 10.1093/brain/awf117) 
``` 

The file is not loaded into this report - because digitisation requires manual clicking, which would prevent the Markdown report from running. However, we will show a chunk of code below on how the csv files are loaded into the R environment.Note that the images from the original source paper used for digitisation are not uploaded in the R projects to avoid copyright infringements. 

```{r, echo=TRUE, eval=TRUE}

# # Read and display the code from DigitiseKaplanMeier.R

code <- readLines("Data/DigitiseKaplanMeier.R")
cat(code[14:42], sep = "\n")
```

### Load CSV files containing manually digitised Kaplan-Meier curves and prepare datasets for analysis

This code chunk loads the csv files that contain the time to event data. For example, the probability of an event at each recorded time point, which was extracted from the Kaplan-Meier curves. Note that we create a dataset for a hypothetical treatment arm. The hypothetical treatment arm is assumed to have a disease modifying effect, which slows the progression of the disease. The time to event is increased by 50% in the hypothetical treatment arm.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}
# Load the manually digitized csv.files for clinical events: aid-required walking, wheelchair confinement, bedridden, and death

AidWalk <- read.csv("Data/TimeToAidWalk.csv")
Wheelchair <- read.csv("Data/TimeToWheelchair.csv")
Bedridden <- read.csv("Data/TimeToBedridden.csv")
Death <- read.csv("Data/TimeToDeath.csv")

#In the Figures all data converge, but due to manual imprecision of clicking. We make sure that the last time point is 1.00, as all Kaplan-Meier Curves converge. For example, the last click during digitisation might cause the last value to be slightly below or over 1.00.

AidWalk$probability[AidWalk$time == max(AidWalk$time)] <- 1
Wheelchair$probability[Wheelchair$time == max(Wheelchair$time)] <- 1
Bedridden$probability[Bedridden$time == max(Bedridden$time)] <- 1
Death$probability[Death$time == max(Death$time)] <- 1

#Also, make sure that the starting point is time 0 and probability 0

AidWalk <- rbind(data.frame(time = 0, probability = 0), AidWalk)
Wheelchair <- rbind(data.frame(time = 0, probability = 0), Wheelchair)
Bedridden <- rbind(data.frame(time = 0, probability = 0), Bedridden)
Death <- rbind(data.frame(time = 0, probability = 0), Death)

#We ensure that each time unit is rounded and unique

AidWalk <- AidWalk %>%
  mutate(
    time = round(time)
  )

Wheelchair <- Wheelchair %>%
  mutate(
    time = round(time)
  )

Bedridden <- Bedridden %>%
  mutate(
    time = round(time)
  )

Death <- Death %>%
  mutate(
    time = round(time)
  )


# Define treatment efficacy. Disease modifying effect (slowing in disease). Time to event increased by approximately 50% by using a hazard rate of 0.67 e.g., 1 / 0.67 = 1.49 . This is one of several ways people can introduce efficacy modification, but we choose this one for simplicity and because it allows us to apply it in both models.

hr_trt_mod <- 0.67

# Define datasets that need treatment modification

AidWalk_trt <- AidWalk
AidWalk_trt$time <- round(AidWalk$time / hr_trt_mod)

Wheelchair_trt <- Wheelchair
Wheelchair_trt$time <- round(Wheelchair$time / hr_trt_mod)

Bedridden_trt <- Bedridden
Bedridden_trt$time <- round(Bedridden$time / hr_trt_mod)

Death_trt <- Death
Death_trt$time <- round(Death$time / hr_trt_mod)

```

### Illustrate the digitised Kaplan-Meier curves.

It is advantageous to compare the digitised Kaplan-Meier curves for similarity with the original Kaplan-Meier curves from the source paper, if re-using this code, to check for clicking errors and similarity. Naturally, only for the natural history of disease (ORIGINAL) data.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

#Plot Kaplan-Meier datasets for natural history of disease 

KM_dataset <- ggplot() +
  geom_step(data = AidWalk, aes(x = time, y = probability, color = "Aid-required walking")) +
  geom_step(data = Wheelchair, aes(x = time, y = probability, color = "Wheelchair")) +
  geom_step(data = Bedridden, aes(x = time, y = probability, color = "Bedridden")) +
  geom_step(data = Death, aes(x = time, y = probability, color = "Death")) +
  theme_minimal() +
  labs(title = "Kaplan-Meier Curves for natural history of disease", x = "Time (years)", y = "Event probability") +
  scale_color_manual(values = c("Aid-required walking" = "blue", "Wheelchair" = "red", "Bedridden" = "green", "Death" = "black")) +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5),
        legend.title = element_blank())

print(KM_dataset)

############### Plot Kaplan-Meier datasets with treatment effect ############################

KM_dataset_trt <- ggplot() + 
  geom_step(data = AidWalk_trt, aes(x = time, y = probability, color = "Aid-required walking")) +
  geom_step(data = Wheelchair_trt, aes(x = time, y = probability, color = "Wheelchair")) +
  geom_step(data = Bedridden_trt, aes(x = time, y = probability, color = "Bedridden")) +
  geom_step(data = Death_trt, aes(x = time, y = probability, color = "Death")) +
  theme_minimal() +
  labs(title = "Kaplan-Meier Curves for treatment arm", x = "Time (years)", y = "Event probability") +
  scale_color_manual(values = c("Aid-required walking" = "blue", "Wheelchair" = "red", "Bedridden" = "green", "Death" = "black")) +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5),
        legend.title = element_blank())

print(KM_dataset_trt) 
```

### Create patient level data (IPD)

In this section, we create datasets for individual patient data (IPD) based on the digitised Kaplan-Meier curves. We add information from the paper e.g., number of patients, for the natural history of disease and hypothetical treatment arm, which can later be used to fit parametric distributions.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Estimate individual patient data for natural history of disease. We know that there were 230 study participants.  

n_used = 230 # Total number of patients

# Construct a dataset for individual patient data (IPD) based on the digitised Kaplan-Meier curves. We included comments to explain the steps of IPD_AidWalk

IPD_AidWalk <- data.frame( 
  pseudo_id = 1:n_used, # The subject IDs 
  status = 1, # Event (status = 1)
  t = NA # Empty column for time
)

# From the natural history of disease study. All patients are dead at 17 years - so we include this as the last time point.

# Reset old_ids for AidWalk dataset
old_ids <- 1  

# Resest probability to handle cumulative events
prev_prob <- 0

#Loop through time points
for (t in 1:17) {
  prob_data <- AidWalk %>% filter(time == t) # Loop through each year
  
  if (nrow(prob_data) != 0) { # If we have data, then: 
    current_prob <- prob_data$probability
    # Calculate number of patients having events at this time point
    n_events <- round(n_used * (current_prob - prev_prob)) # Assign events, but only the new ones.
    
    # Determine end index for assignment
    end_idx <- min(old_ids + n_events - 1, n_used) #Ensure we do not assign to more than 230 patients.
    
    # Assign time t to these patients
    if (end_idx >= old_ids) {
      IPD_AidWalk[old_ids:end_idx, "t"] <- t 
    }
    
    # Update old_ids and previous probability
    old_ids <- end_idx + 1 # Move to next patient
    prev_prob <- current_prob # Update previous probability
    
    # If we've assigned times to all patients, break out of the loop
    if (old_ids > n_used) break # Stop loop when 230 patients have been looped through.
  }
}

# Assign the maximum time to any remaining patients without assigned times
if (old_ids <= n_used) {
  IPD_AidWalk[old_ids:n_used, "t"] <- max(AidWalk$time) # This is our safety mechanism, should there in theory be unassigned events to subjects, then they will eventually experience the event at maximum time. IN other words, our model assumption is that patients will eventually experience the event. We do this across all events. 
}

# For Wheelchair

IPD_Wheelchair <- data.frame(
  pseudo_id = 1:n_used,
  status = 1,
  t = NA
)

# Reset old_ids for Wheelchair dataset
old_ids <- 1
prev_prob <- 0

for (t in 1:17) {
  prob_data <- Wheelchair %>% filter(time == t)
  
  if (nrow(prob_data) != 0) {
    current_prob <- prob_data$probability
    n_events <- round(n_used * (current_prob - prev_prob))
    end_idx <- min(old_ids + n_events - 1, n_used)
    
    if (end_idx >= old_ids) {
      IPD_Wheelchair[old_ids:end_idx, "t"] <- t
    }
    
    old_ids <- end_idx + 1
    prev_prob <- current_prob
    
    if (old_ids > n_used) break
  }
}

if (old_ids <= n_used) {
  IPD_Wheelchair[old_ids:n_used, "t"] <- max(Wheelchair$time)
}

# For Bedridden

IPD_Bedridden <- data.frame(
  pseudo_id = 1:n_used,
  status = 1,
  t = NA
)

# Reset old_ids for Bedridden dataset
old_ids <- 1
prev_prob <- 0

for (t in 1:17) {
  prob_data <- Bedridden %>% filter(time == t)
  
  if (nrow(prob_data) != 0) {
    current_prob <- prob_data$probability
    n_events <- round(n_used * (current_prob - prev_prob))
    end_idx <- min(old_ids + n_events - 1, n_used)
    
    if (end_idx >= old_ids) {
      IPD_Bedridden[old_ids:end_idx, "t"] <- t
    }
    
    old_ids <- end_idx + 1
    prev_prob <- current_prob
    
    if (old_ids > n_used) break
  }
}

if (old_ids <= n_used) {
  IPD_Bedridden[old_ids:n_used, "t"] <- max(Bedridden$time)
}

# For Death 

IPD_Death <- data.frame(
  pseudo_id = 1:n_used,
  status = 1,
  t = NA
)

# Reset old_ids for Death dataset
old_ids <- 1
prev_prob <- 0

for (t in 1:17) {
  prob_data <- Death %>% filter(time == t)
  
  if (nrow(prob_data) != 0) {
    current_prob <- prob_data$probability
    n_events <- round(n_used * (current_prob - prev_prob))
    end_idx <- min(old_ids + n_events - 1, n_used)
    
    if (end_idx >= old_ids) {
      IPD_Death[old_ids:end_idx, "t"] <- t
    }
    
    old_ids <- end_idx + 1
    prev_prob <- current_prob
    
    if (old_ids > n_used) break
  }
}

if (old_ids <= n_used) {
  IPD_Death[old_ids:n_used, "t"] <- max(Death$time)
}


################## Create datasets for treatment arm ###########################################

## For AidWalk_trt. Note that the data from the original publication remains the same, but for the hypothetical treatment arm all patients are dead at time 25.5, which is why we set t in 1:26 in the loop below.

IPD_AidWalk_trt <- data.frame(
  pseudo_id = 1:n_used,
  status = 1,
  t = NA
)

# Reset old_ids for each dataset
old_ids <- 1  # Start from 1

# Store previous probability to handle time points with no data
prev_prob <- 0

for (t in 1:26) {
  prob_data <- AidWalk_trt %>% filter(time == t)
  
  if (nrow(prob_data) != 0) {
    current_prob <- prob_data$probability
    # Calculate number of patients having events at this time point
    n_events <- round(n_used * (current_prob - prev_prob))
    
    # Determine end index for assignment
    end_idx <- min(old_ids + n_events - 1, n_used)
    
    # Assign time t to these patients
    if (end_idx >= old_ids) {
      IPD_AidWalk_trt[old_ids:end_idx, "t"] <- t
    }
    
    # Update old_ids and previous probability
    old_ids <- end_idx + 1
    prev_prob <- current_prob
    
    # If we've assigned times to all patients, break out of the loop
    if (old_ids > n_used) break
  }
}

# Assign the maximum time to any remaining patients without assigned times
if (old_ids <= n_used) {
  IPD_AidWalk_trt[old_ids:n_used, "t"] <- max(AidWalk_trt$time)
}


## For Wheelchair_trt

IPD_Wheelchair_trt <- data.frame(
  pseudo_id = 1:n_used,
  status = 1,
  t = NA
)

# Reset old_ids for Wheelchair_trt dataset
old_ids <- 1
prev_prob <- 0

for (t in 1:26) {
  prob_data <- Wheelchair_trt %>% filter(time == t)
  
  if (nrow(prob_data) != 0) {
    current_prob <- prob_data$probability
    n_events <- round(n_used * (current_prob - prev_prob))
    end_idx <- min(old_ids + n_events - 1, n_used)
    
    if (end_idx >= old_ids) {
      IPD_Wheelchair_trt[old_ids:end_idx, "t"] <- t
    }
    
    old_ids <- end_idx + 1
    prev_prob <- current_prob
    
    if (old_ids > n_used) break
  }
}

if (old_ids <= n_used) {
  IPD_Wheelchair_trt[old_ids:n_used, "t"] <- max(Wheelchair_trt$time)
}



## For Bedridden_trt

IPD_Bedridden_trt <- data.frame(
  pseudo_id = 1:n_used,
  status = 1,
  t = NA
)

# Reset old_ids for Bedridden_trt dataset
old_ids <- 1
prev_prob <- 0

for (t in 1:26) {
  prob_data <- Bedridden_trt %>% filter(time == t)
  
  if (nrow(prob_data) != 0) {
    current_prob <- prob_data$probability
    n_events <- round(n_used * (current_prob - prev_prob))
    end_idx <- min(old_ids + n_events - 1, n_used)
    
    if (end_idx >= old_ids) {
      IPD_Bedridden_trt[old_ids:end_idx, "t"] <- t
    }
    
    old_ids <- end_idx + 1
    prev_prob <- current_prob
    
    if (old_ids > n_used) break
  }
}

if (old_ids <= n_used) {
  IPD_Bedridden_trt[old_ids:n_used, "t"] <- max(Bedridden_trt$time)
}


## For Death_trt

IPD_Death_trt <- data.frame(
  pseudo_id = 1:n_used,
  status = 1,
  t = NA
)

# Reset old_ids for Death_trt dataset
old_ids <- 1
prev_prob <- 0

for (t in 1:26) {
  prob_data <- Death_trt %>% filter(time == t)
  
  if (nrow(prob_data) != 0) {
    current_prob <- prob_data$probability
    n_events <- round(n_used * (current_prob - prev_prob))
    end_idx <- min(old_ids + n_events - 1, n_used)
    
    if (end_idx >= old_ids) {
      IPD_Death_trt[old_ids:end_idx, "t"] <- t
    }
    
    old_ids <- end_idx + 1
    prev_prob <- current_prob
    
    if (old_ids > n_used) break
  }
}

if (old_ids <= n_used) {
  IPD_Death_trt[old_ids:n_used, "t"] <- max(Death_trt$time)
}



```

### Fitting distributions

We fit distributions, first for the natural history of disease and for the hypothetical treatment arm.

### Natural history of disease

We fit parametric distributions for all events for natural history of disease. It is visually clear that Weibull and logistic best fit the data. When applying Akaikes Information Criterion and Bayes Information Criterion, the Weibull distribution is the best fit with lowest AIC and BIC for all events.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Function to fit parametric distributions and plot survival curves
FitPlot <- function(IPD_data, title) {
  
  # Fit parametric distributions: Weibull, logistic, log-normal, and exponential distributions 
  
  fit_weib <- survreg(Surv(IPD_data$t, IPD_data$status) ~ 1, dist = "weibull")
  fit_llogis <- survreg(Surv(IPD_data$t, IPD_data$status) ~ 1, dist = "logistic")
  fit_lnorm <- survreg(Surv(IPD_data$t, IPD_data$status) ~ 1, dist = "gaussian")
  fit_exp <- survreg(Surv(IPD_data$t, IPD_data$status) ~ 1, dist = "exponential")
  
  # Define time points for estimation
  time_points <- seq(0, max(IPD_data$t), by = 1)
  
  # Calculate survival probabilities for each distribution
  surv_prob_weib <- pweibull(time_points, shape = 1 / fit_weib$scale, scale = exp(fit_weib$coefficients), lower.tail = FALSE)
  surv_prob_llogis <- plogis(time_points, location = fit_llogis$coefficients, scale = fit_llogis$scale, lower.tail = FALSE)
  surv_prob_lnorm <- plnorm(time_points, meanlog = fit_lnorm$coefficients, sdlog = fit_lnorm$scale, lower.tail = FALSE)
  surv_prob_exp <- pexp(time_points, rate = 1 / exp(fit_exp$coefficients), lower.tail = FALSE)
  
  # Combine the data into a single data frame
  plot_data <- data.frame(
    time = rep(time_points, 4),
    survival = c(surv_prob_weib, surv_prob_llogis, surv_prob_lnorm, surv_prob_exp),
    distribution = rep(c("Weibull", "Logistic", "Log-normal", "Exponential"), each = length(time_points))
  )
  
  # Plot the survival curves using ggplot2
  plot <- ggplot(plot_data, aes(x = time, y = survival, color = distribution)) +
    geom_line() +
    theme_minimal() +
    labs(title = paste("Fitted Survival Curves for", title), x = "Time (years)", y = "Survival Probability") +
    scale_color_manual(values = c("Weibull" = "blue", "Logistic" = "red", "Log-normal" = "green", "Exponential" = "purple")) +
    theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5), legend.title = element_blank())
  
  # Evaluate for AIC and BIC
  AIC <- c(AIC(fit_weib), AIC(fit_llogis), AIC(fit_lnorm), AIC(fit_exp))
  BIC <- c(BIC(fit_weib), BIC(fit_llogis), BIC(fit_lnorm), BIC(fit_exp))
  
  # Create a data frame for model comparison
  ModelCriteria <- data.frame(
    Distribution = c("Weibull", "Logistic", "Log-normal", "Exponential"),
    AIC = AIC,
    BIC = BIC
  )
  
  # Print table with AIC and BIC
  table <- knitr::kable(ModelCriteria, caption = paste("Model Comparison using AIC and BIC for", title), format = "html", align = 'c') %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                  full_width = TRUE, position = "center")
  
  list(plot = plot, table = table)
}

# Fit and plot for AidWalk
results_AidWalk <- FitPlot(IPD_AidWalk, "Aid-required walking")
print(results_AidWalk$plot)
results_AidWalk$table

# Fit and plot for Wheelchair
results_Wheelchair <- FitPlot(IPD_Wheelchair, "Wheelchair")
print(results_Wheelchair$plot)
results_Wheelchair$table

# Fit and plot for Bedridden
results_Bedridden <- FitPlot(IPD_Bedridden, "Bedridden")
print(results_Bedridden$plot)
results_Bedridden$table

# Fit and plot for Death
results_Death <- FitPlot(IPD_Death, "Death")
print(results_Death$plot)
results_Death$table
```

### Treatment arm

Not surprisingly. The same distributions are the best fit for the treatment arm. Weibull and logistic distributions are the best fit for all events. The Weibull distribution is the best fit with lowest AIC and BIC for all events.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Function to fit and plot distributions for treatment arm 

FitPlot_trt <- function(IPD_data_trt, title) {
  
  # Fit parametric distributions: Weibull, logistic, log-normal, and exponential distributions 
  
  fit_weib_trt <- survreg(Surv(IPD_data_trt$t, IPD_data_trt$status) ~ 1, dist = "weibull")
  fit_llogis_trt <- survreg(Surv(IPD_data_trt$t, IPD_data_trt$status) ~ 1, dist = "logistic")
  fit_lnorm_trt <- survreg(Surv(IPD_data_trt$t, IPD_data_trt$status) ~ 1, dist = "gaussian")
  fit_exp_trt <- survreg(Surv(IPD_data_trt$t, IPD_data_trt$status) ~ 1, dist = "exponential")
  
  # Define time points for estimation
  time_points_trt <- seq(0, max(IPD_data_trt$t), by = 1)
  
  # Calculate survival probabilities for each distribution
  surv_prob_weib_trt <- pweibull(time_points_trt, shape = 1 / fit_weib_trt$scale, scale = exp(fit_weib_trt$coefficients), lower.tail = FALSE)
  surv_prob_llogis_trt <- plogis(time_points_trt, location = fit_llogis_trt$coefficients, scale = fit_llogis_trt$scale, lower.tail = FALSE)
  surv_prob_lnorm_trt <- plnorm(time_points_trt, meanlog = fit_lnorm_trt$coefficients, sdlog = fit_lnorm_trt$scale, lower.tail = FALSE)
  surv_prob_exp_trt <- pexp(time_points_trt, rate = 1 / exp(fit_exp_trt$coefficients), lower.tail = FALSE)
  
  # Combine the data into a single data frame
  plot_data_trt <- data.frame(
    time = rep(time_points_trt, 4),
    survival = c(surv_prob_weib_trt, surv_prob_llogis_trt, surv_prob_lnorm_trt, surv_prob_exp_trt),
    distribution = rep(c("Weibull", "Logistic", "Log-normal", "Exponential"), each = length(time_points_trt))
  )
  
  # Plot combined dataset
  plot_trt <- ggplot(plot_data_trt, aes(x = time, y = survival, color = distribution)) +
    geom_line() +
    theme_minimal() +
    labs(title = paste("Fitted Survival Curves for", title), x = "Time (years)", y = "Survival Probability") +
    scale_color_manual(values = c("Weibull" = "blue", "Logistic" = "red", "Log-normal" = "green", "Exponential" = "purple")) +
    theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5), legend.title = element_blank())
  
  # Evaluate for AIC and BIC
  AIC_trt <- c(AIC(fit_weib_trt), AIC(fit_llogis_trt), AIC(fit_lnorm_trt), AIC(fit_exp_trt))
  BIC_trt <- c(BIC(fit_weib_trt), BIC(fit_llogis_trt), BIC(fit_lnorm_trt), BIC(fit_exp_trt))
  
  # Data frame for model comparison
  ModelCriteria_trt <- data.frame(
    Distribution = c("Weibull", "Logistic", "Log-normal", "Exponential"),
    AIC = AIC_trt,
    BIC = BIC_trt
  )
  
  # Print table with AIC and BIC
  table_trt <- knitr::kable(ModelCriteria_trt, caption = paste("Model Comparison using AIC and BIC for", title), format = "html", align = 'c') %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                  full_width = TRUE, position = "center")
  
  list(plot = plot_trt, table = table_trt)
}
  
  #Fit and plot for AidWalk_trt
  results_AidWalk_trt <- FitPlot_trt(IPD_AidWalk_trt, "Aid-required walking")
  print(results_AidWalk_trt$plot)
  results_AidWalk_trt$table
  
  # Fit and plot for Wheelchair_trt
  results_Wheelchair_trt <- FitPlot_trt(IPD_Wheelchair_trt, "Wheelchair")
  print(results_Wheelchair_trt$plot)
  results_Wheelchair_trt$table
  
  # Fit and plot for Bedridden_trt
  results_Bedridden_trt <- FitPlot_trt(IPD_Bedridden_trt, "Bedridden")
  print(results_Bedridden_trt$plot)
  results_Bedridden_trt$table
  
  # Fit and plot for Death_trt
  results_Death_trt <- FitPlot_trt(IPD_Death_trt, "Death")
  print(results_Death_trt$plot)
  results_Death_trt$table
  
```

# Partitioned Survival Model

We use the hesim package developed for modelling in R

```         
Incerti D, Jansen J (2021). “hesim: Health Economic Simulation Modeling and Decision Analysis.” 2102.09437, https://arxiv.org/abs/2102.09437.
```

We prepare data and fit parametric distributions for the partitioned survival model. In addition, we also define input parameters for the partitioned survival model. The model has a cycle length of one year, because of the long follow-up data.

## Define model parameters

So far, we have called the arms: natural history of disease and hypothetical treatment arm, but for the cost-effectiveness analysis. We make the assumption that natural history of disease is best Best Supportive Care (BSC) and the hypothetical treatment arm is a hypothetical drug with best supportive care (Hypothetical Drug & BSC). Note that a state for Death is not added, because the R package inherently knows that this will be the last health state for a partitioned survival model.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

library(data.table)
library(hesim)

set.seed(11) #Setting a seed for replication purposes, which will also apply to the Markov model, which is built after the partitioned survival model.

# Define strategies (arms)
strategies <- data.table(strategy_id = c(1, 2),
                         strategy_name = c("BSC", "Hypothetical Drug & BSC"))

# Print treatment strategies 

kable(strategies, caption = "Treatment strategies", format = "html", align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = TRUE, position = "center")
  
# The time to event data was only available from Watanabe et al 2022, which reported approx. 43% females, mean age = 54.4, and standard deviation = 8.3 years. One could add information from the paper e.g., age and female and use as covariates for survival models or regression of costs as per an online example:https://cran.r-project.org/web/packages/hesim/vignettes/psm.html. In this case, we do not do it, because we are aiming to triangulate modelling results, and we do not want to add arbitrary covariates. Nonetheless, we provide an example of how it can be done without using them.    

# For example, we include the covariates, but they will not be used in the model. 

patients <- data.table(patient_id = 1:460, #We 230 patients from each arm.
                      age = round(rnorm(460, mean = 54.4, sd = 8.3),0),   
                                  female = rbinom(380, size = 1, prob = 0.43)
)
                      
 
# These states represent progression in terms of events. However, to align with nomenclature on partitioned survival models. We technically have four curves: Aid-required walking, Wheelchair, Bedridden, and Overall Survival (event is death). Thus, the states become able to walk (before an event), aid-required walking, wheelchair confinement, bedridden, and death. 

states <- data.table(state_id = seq(1, 4),
                     state_name = c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden"), 
                     stringsAsFactors = FALSE)

# Print health states
kable(states, caption = "Health states", format = "html", align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = TRUE, position = "center")

  
hesim_data <- hesim_data(strategies = strategies, 
                        patients = patients,
                         states = states)

# print(hesim_data)

labs <- get_labels(hesim_data)

```

## Parameter estimation for survival models

A dataset that is compatible with the hesim package is constructed. We fit Weibull models for each endpoint, because we previously found that the Weibull distribution was the best fit for all events.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Dataset for BSC arm

time_to_event_data <- IPD_AidWalk %>%
  rename(AidWalk_status = status, AidWalk_time = t) %>%
  left_join(IPD_Wheelchair %>% rename(Wheelchair_status = status, Wheelchair_time = t), by = "pseudo_id") %>%
  left_join(IPD_Bedridden %>% rename(Bedridden_status = status, Bedridden_time = t), by = "pseudo_id") %>%
  left_join(IPD_Death %>% rename(Death_status = status, Death_time = t), by = "pseudo_id") %>%
  mutate(strategy_name = "BSC") %>%
  rename(patient_id = pseudo_id) %>%
  left_join(patients, by = "patient_id") %>%
  dplyr::select(patient_id, age, female, strategy_name, dplyr::everything())

# Ensure events happen sequentially to follow disease progression logic (AidWalk → Wheelchair → Bedridden → Death)
time_to_event_data <- time_to_event_data %>%
  mutate(
    Wheelchair_time = pmax(Wheelchair_time, AidWalk_time),
    Bedridden_time  = pmax(Bedridden_time, Wheelchair_time),
    Death_time      = pmax(Death_time, Bedridden_time)
  )


# Dataset for treatment arm

time_to_event_data_trt <- IPD_AidWalk_trt %>%
  rename(AidWalk_status = status, AidWalk_time = t) %>%
  left_join(IPD_Wheelchair_trt %>% rename(Wheelchair_status = status, Wheelchair_time = t), by = "pseudo_id") %>%
  left_join(IPD_Bedridden_trt %>% rename(Bedridden_status = status, Bedridden_time = t), by = "pseudo_id") %>%
  left_join(IPD_Death_trt %>% rename(Death_status = status, Death_time = t), by = "pseudo_id") %>%
  mutate(strategy_name = "Hypothetical Drug & BSC") %>%
  rename(patient_id = pseudo_id) %>%
  mutate(patient_id = patient_id + max(time_to_event_data$patient_id, na.rm = TRUE)) %>% # Adjust patient_id and make sequential to avoid overwriting patients from time_to_event_data and make each of the patients from each treatment arm unique.
  left_join(patients, by = "patient_id") %>%
  dplyr::select(patient_id, age, female, strategy_name, dplyr::everything())

# Ensure events happen sequentially to follow disease progression logic (AidWalk → Wheelchair → Bedridden → Death)
time_to_event_data_trt <- time_to_event_data_trt %>%
  mutate(
    Wheelchair_time = pmax(Wheelchair_time, AidWalk_time),
    Bedridden_time  = pmax(Bedridden_time, Wheelchair_time),
    Death_time      = pmax(Death_time, Bedridden_time)
  )

# Combine the two datasets

surv_est_data <- rbind(time_to_event_data, time_to_event_data_trt)

# Estimate parameters

fit_weib_AidWalk <- flexsurvreg(Surv(AidWalk_time, AidWalk_status) ~ strategy_name, 
  data = surv_est_data,
  dist = "weibull")

fit_weib_Wheelchair <- flexsurvreg(
  Surv(Wheelchair_time, Wheelchair_status) ~ strategy_name,  
  data = surv_est_data,
  dist = "Weibull")

fit_weib_bedridden <- flexsurvreg(
  Surv(Bedridden_time, Bedridden_status) ~ strategy_name, 
  data = surv_est_data,
  dist = "weibull")

fit_weib_death <- flexsurvreg(
  Surv(Death_time, Death_status) ~ strategy_name, 
  data = surv_est_data,
  dist = "weibull")

psfit <- flexsurvreg_list(fit_weib_AidWalk, fit_weib_Wheelchair, fit_weib_bedridden, fit_weib_death)


```

## Define utilities and costs parameters for drug and health states

For the state able to walk, we assume from triangulation purposes that this state correspond to UMSARS IV item 1 + 2 (mostly or not completely independent). Similarly, we use the aggregated costs for UMSARS IV item 1 + 2 from 

``` 
Winter et al 2011 Health-related quality of life in multiple system atrophy and progressive supranuclear palsy' (DOI: 10.1007/s00415-011-6028-7).
``` 

The utility data is generated from individual patient level data, which cannot be shared, but is stored as a csv file. Moreover, we add disutilities directly in the code from literature to account for short-term events that may not have been captured by the six-monthly eq-5d measurements in the patient level data. However, for costs, we provide an R file that shows the generation of cost estimates.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Load health state utilities (EMSA IPD data) from csv. file

utilities <- read.csv("data/utilities.csv") 

# Construct disutilities which are applied to each health state, which are from literature, and applied because the utilities are captured at six-monthly intervals, and thus disutilities are needed to account for shortterm events. From Wenning et al. 2013, we obtain the following probabilities: Hypotension disorders (orthostatic hypotension) 56.7 %, urinary or bladder disorders (incomplete bladder emptying) 51.1%, bowel disorders (constipation) 58.2%. From the literature we estimate disutilities: Hypotensions disorders -0.067 (calculated from Xiao et al 2022), urinary or bladder disorders -0.0054 (Sulivan, Slejko, Sculpher and Ghushchyan, 2011)), bowel disorders -0.194 (Calculated from Falk Hvidberg and Hernández Alava, 2023). Moreover, we adjust with the treatment modifier trt_mod_dis, which provides a 50 % reduction in events (disutilities)

rr_trt_mod_e <- 0.5 # Relative risk treament modifier for events

p_UD <- 0.511 # Probability of urinary or bladder disorders
p_HD <- 0.567 # Probability hypotension disorders
p_BD <- 0.582 # Probability bowel disorders

du_UD <- 0.0054 # Disutility urinary or bladder disorders
du_HD <- 0.067 # Disutility hypotension disorders
du_BD <- 0.194 # Disutility bowel disorders

disutilities <- -c(p_UD * du_UD + p_HD * du_HD + p_BD * du_BD)
disutilities_trt <- -c(p_UD * du_UD * rr_trt_mod_e + p_HD * du_HD * rr_trt_mod_e + p_BD * du_BD * rr_trt_mod_e)


# We implement a similar approach as in the Markov, because although we make sure that mean is positive if distributions are assigned in a previously used chunk, alpha and beta can still be negative. Thus, we implement a piece of code that focus on this rather than means. Note that we do not assign distributions to disutilities, but instead the utility uncertainty is assigned to the utilities.

check_dist_utility <- function (mean, sd) {
  if (mean <= 0 || mean >= 1) { # First check mean is between 0 and 1
    return("fixed")
  }
    # Calculate parameters
   
    var <- sd^2
    alpha <- mean * (mean * (1 - mean) / var - 1)
    beta <- (1 - mean) * ((mean * (1 - mean)) / var - 1)
    
    if (alpha <= 0 || beta <= 0) { # Check if alpha and beta are negative or positive. If negative, we fix the values. 
      return("fixed")
    } else {
      return("beta")
    } 
  }

# Vector of utility means
bsc_means <- utilities$Mean_Index_Score + disutilities
trt_means <- ifelse(states$state_id == 4, 
                   utilities$Mean_Index_Score + disutilities, # Since treatment is stopped at state 4 - bedridden, we do not apply a reduction in clinical events (disutility)
                   utilities$Mean_Index_Score + disutilities_trt)

# Build utility table with validated distributions
utility_tbl <- stateval_tbl(
  data.table(
    strategy_id = rep(c(1, 2), each = length(states$state_id)),
    state_id = rep(states$state_id, times = 2),
    mean = c(bsc_means, trt_means),
    sd = rep(utilities$Standard_Deviation, 2),
    dist = c(
      sapply(1:length(states$state_id), function(i) check_dist_utility(bsc_means[i], utilities$Standard_Deviation[i])),
      sapply(1:length(states$state_id), function(i) check_dist_utility(trt_means[i], utilities$Standard_Deviation[i]))
    )
  )
)

# Print utilities 

kable(utility_tbl, caption = "Utilities for health states", format = "html", align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = TRUE, position = "center")


# Load annual costs adjusted for inflation and converted to pounds sterling

costs <- read.csv("Data/AnnualAdjustedCosts.csv") 

# Display code in report

# cost_code <- readLines("Data/GenerateCosts.R") # Not needed for now. Thus, commented out.  

# cost_code

# Define health state costs

cost_tbl <- stateval_tbl(
  data.table(state_id = states$state_id,
             mean = costs$Total,
             se = costs$StandardError
             ),
            dist = "gamma"
  )

# Add gamma distribution parameters table for transparency
cost_params <- data.frame(
  State = states$state_name,
  Mean = costs$Total,
  SE = costs$StandardError,
  Distribution = "gamma",
  Shape = (costs$Total/costs$StandardError)^2,  # Shape = (mean/SE)²
  Scale = (costs$StandardError)^2/costs$Total   # Scale = SE²/mean
)

kable(cost_params, 
      caption = "Gamma Distribution Parameters for Health State Costs", 
      format = "html", 
      digits = c(0, 0, 0, 0, 2, 4)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = TRUE, position = "center")

# Define treatment costs

Drug <- 12000 # Annual hypothetical drug cost


# In our study example we do not treat in the Bedridden state. 

drug_cost_tbl <- stateval_tbl(
   data.table(
     strategy_id = rep(strategies$strategy_id, each = nrow(states)),
     state_id = rep(states$state_id, times = nrow(strategies)),
     est = c(
       rep(0, nrow(states)),                            # Strategy 1 (BSC): all states get 0 drug cost
       ifelse(states$state_id == 4, 0, Drug)             # Strategy 2: state 4 gets 0, others use drug cost
     )
   ),
   dist = "fixed"
 )


# Print treatment costs

kable(drug_cost_tbl, caption = "Treatment costs", format = "html", align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = TRUE, position = "center")

```

## Constructing individual components of the cost-effectiveness model

In accordance with the hesim package - models are constructed for sets of parameters and lastly bound together as a partitioned survival model.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}


# Define number of samples

n_samples <- 500 # My current PC struggles when using 1000 samples, which is why we use 500 samples :(

# Create survival models

surv_input_data <- hesim::expand(hesim_data, by = c("strategies", "patients"))

survmods <- create_PsmCurves(psfit, input_data = surv_input_data, n = n_samples, 
                             uncertainty = "normal", est_data = surv_est_data)



# Create utility model - the hesim package will use the mean values which is consistent with the approach in the Markov model where a manual beta parameter approach was used.

utilitymod <- create_StateVals(utility_tbl, n = n_samples, hesim_data = hesim_data)


# Create cost models

## First the drug costs

drugcostmod <- create_StateVals(drug_cost_tbl, n = n_samples, hesim_data = hesim_data)

## Then the health state costs

medcostmod <- create_StateVals(cost_tbl, n = n_samples, hesim_data = hesim_data)

# Combining all statistical models

psm <- Psm$new(survival_models = survmods, utility_mod = utilitymod, cost_models = list(medcostmod, drugcostmod)) 

```

## Simulate outcomes

We simulate survival curves generating a plot of survival curves averaged across patients by treatment strategy

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

times <- seq (0, 31, by = 1)
psm$sim_survival(t = times)

# Survival plot for all strategies

labs$curve <- c("Aid-required walking" = 1, "Wheelchair confinement" = 2, "Bedridden" = 3, "Death" = 4)
autoplot(psm$survival_, labels = labs,
     ci = TRUE, ci_style = "ribbon") +
  scale_x_continuous(breaks = seq(0, max(times), 2)) +
  scale_fill_manual(values = c("Aid-required walking" = "#1f77b4",
                 "Wheelchair confinement" = "#ff7f0e",
                 "Bedridden" = "#2ca02c",
                 "Death" = "#d62728")) +
  theme_minimal() +
  theme(legend.position = "bottom",
    plot.title = element_text(hjust = 0.5),
    legend.title = element_blank())


```

## Health state occupancies

We simulate state occupancy here, which is important for assigning utilities and costs at various time points.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}


# Simulate
psm$sim_stateprobs()


###########################################################################################

# Plotting aggregated state probabilities 

# Aggregate state probabilities over PSA samples and patients for the PSM
stateprobs_psm_agg <- psm$stateprobs_[, .(prob = mean(prob)), by = .(t, state_id, strategy_id)]

# Map state_id to state name and define factor levels (reverse order for stacking)
state_map_psm <- data.table::data.table(
  state_id = c(1, 2, 3, 4, 5),
  state_name = c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden", "Death")
)
stateprobs_psm_agg <- merge(stateprobs_psm_agg, state_map_psm, by = "state_id", all.x = TRUE)
stateprobs_psm_agg[, state_name := factor(state_name, 
  levels = c("Death", "Bedridden", "Wheelchair confinement", "Aid-required walking", "Able to walk")
)]

# Define strategy labels assuming strategy_id 1 = BSC and 2 = Hypothetical Drug & BSC
stateprobs_psm_agg[, strategy := factor(strategy_id, levels = c(1,2),
                                          labels = c("BSC", "Hypothetical Drug & BSC"))]

# Plot aggregated state occupation for the PSM
ggplot(stateprobs_psm_agg, aes(x = t, y = prob, fill = state_name)) +
  geom_area(alpha = 0.65) +
  facet_wrap(~strategy, ncol = 2) +
  labs(title = "PSM – Health State Occupancy Over Time",
       x = "Time (Years)",
       y = "Proportion in State") +
scale_fill_manual(name = "",
                  values = c("Able to walk" = "#74c476", 
                             "Aid-required walking" = "#a1d99b", 
                             "Wheelchair confinement" = "#fd8d3c", 
                             "Bedridden" = "#e34a33",
                             "Death" = "#969696"),
breaks = c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden", "Death")) +
  theme_minimal() +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5))


```

## Probabilistic results

Results for the probabilistic cost-effectiveness analysis.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

psm$sim_qalys(dr = 0.035)
psm$sim_costs(dr = 0.035)

# Calculate ICER

ce_sim <- psm$summarize()


wtp <- seq(0, 200000, 500) # hesim package seems to impose an internal limit of 200,000, which we will use. 
cea_pw_out <- cea_pw(ce_sim, comparator = 1, 
                     dr_qalys = 0.035, dr_costs = 0.035, wtp)

# Report standard ICER by hesim package for sanity check 

# (icer(cea_pw_out, k = 100000, labels = labs, pivot_from = "strategy", drop_grp = TRUE, pretty_name = TRUE))

# Report bespoke ICER table 

total_costs <- ce_sim$costs %>% filter(category == "total")
ce_sim_summary <- merge(total_costs, ce_sim$qalys, by = c("sample", "strategy_id", "grp_id"))

# Calculate means by strategy
icer_data <- ce_sim_summary %>%
  group_by(strategy_id) %>%
  summarise(
    Costs = mean(costs),
    QALYs = mean(qalys)
  )

# Calculate ICER
inc_costs <- icer_data$Costs[2] - icer_data$Costs[1]
inc_qalys <- icer_data$QALYs[2] - icer_data$QALYs[1]
icer_value <- inc_costs / inc_qalys

# Create final table with matching format
icer_table <- data.frame(
  Strategy = c("Hypothetical Drug & BSC", "BSC"),
  Costs = c(icer_data$Costs[2], icer_data$Costs[1]),
  QALYs = c(icer_data$QALYs[2], icer_data$QALYs[1]),
  ICER = c(NA, icer_value)
)

# Format values & rename for easier identification later
icer_table_psa_psm <- icer_table %>%
  mutate(
    Costs = round(Costs, 0),
    QALYs = round(QALYs, 2),
    ICER = ifelse(is.na(ICER), NA, round(ICER, 0))
  )

# Create table with the deterministic table
kable(icer_table_psa_psm, 
      caption = paste("ICER(£ per QALY) = ", format(round(icer_value, 0), big.mark=",")), 
      format = "html", 
      align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                           full_width = TRUE)

# Create cost-effectiveness plane that fits the data
  
  strategy_factor <- function(x) {
  factor(x, levels = 1:2, labels = c(strategy_name = "BSC", "Hypothetical Drug & BSC"))
  }

  format_dollar <- function(x) {
    paste0("£ ", formatC(x, format = "d", big.mark = ","))
  }  
  
ylim <- max(cea_pw_out$delta[, ic]) * 1.1
xlim <- ceiling(max(cea_pw_out$delta[, ie]) * 1.1)
ggplot(cea_pw_out$delta,
       aes(x = ie, y = ic, col = strategy_factor(strategy_id))) +
  geom_jitter(size = .5)  +
  xlab("Incremental QALYs") +
  ylab("Incremental cost") +
  scale_y_continuous(limits = c(-22000, ylim), #here you can -ylim to 0
                     labels = format_dollar) +
  scale_x_continuous(limits = c(-xlim, xlim), breaks = seq(-10, 10, 1)) +
  theme(legend.position = "bottom") +
  scale_colour_discrete(name = "Strategy") +
  geom_abline(slope = 30000, linetype = "dashed") +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0) 


# Create cost-effectiveness acceptability curve


ggplot(cea_pw_out$ceac,
       aes(x = k, y = prob, col = strategy_factor(strategy_id))) +
  geom_line()  +
  xlab("Willingness to pay") +
  ylab("Probability most cost-effective") +
  scale_x_continuous(breaks =  seq(0, max(wtp), length.out = 6),
                     label = format_dollar) +
  theme(legend.position = "bottom") +
  scale_colour_discrete(name = "Strategy")

```

### Expected Value of perfect information

In this section we conduct an analysis of the expected value of perfect information on the individual level.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# We calculate EVPI

cea_out <- cea(ce_sim, dr_qalys = 0.035, dr_costs = 0.035)

# plot_evpi(cea_out)

# Calculate EVPI for each WTP threshold
evpi_data <- data.frame(
  wtp = cea_out$evpi$k,
  evpi = cea_out$evpi$evpi
)
# Create EVPI plot using ggplot2
ggplot(evpi_data, aes(x = wtp, y = evpi)) +
   geom_line() +
   xlab("Willingness to pay") +
   ylab("Expected value of perfect information") +
   scale_x_continuous(breaks = seq(0, max(wtp), length.out = 6),
                     labels = format_dollar) +
   scale_y_continuous(labels = format_dollar) +
   theme_minimal() +
   theme(legend.position = "bottom")


```

## Deterministic results

We can estimate a deterministic result by simulating the model with a single sample without sampling uncertainty "none", which means that the model parameters are kept constant and no distribution for sampling is assigned.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Deterministic results for the PSM model.

surv_input_data_det <- hesim::expand(hesim_data, by = c("strategies", "patients"))

# Samples = 1 (Deterministic)

n_samples_det <- 1



# Survival models with no uncertainty (point estimates)
survmods_det <- create_PsmCurves(psfit, input_data = surv_input_data_det, 
                                n = n_samples_det,  # Single sample
                                uncertainty = "none", # No uncertainty sampling. 
                                est_data = surv_est_data)

# Utility model with fixed values (no probabilistic sampling)
utilitymod_det <- create_StateVals(utility_tbl, n = n_samples_det, 
                                  hesim_data = hesim_data)

# Cost models with fixed values
drugcostmod_det <- create_StateVals(drug_cost_tbl, n = n_samples_det, 
                                   hesim_data = hesim_data)

medcostmod_det <- create_StateVals(cost_tbl, n = n_samples_det, 
                                  hesim_data = hesim_data)

# Combine into deterministic PSM
psm_det <- Psm$new(survival_models = survmods_det, 
                   utility_mod = utilitymod_det, 
                   cost_models = list(medcostmod_det, drugcostmod_det))

# Simulate outcomes
times_det <- seq(0, 31, by = 1)
psm_det$sim_survival(t = times_det)
psm_det$sim_stateprobs()
psm_det$sim_qalys(dr = 0.035)
psm_det$sim_costs(dr = 0.035)

# Get deterministic results
ce_det <- psm_det$summarize()

# Calculate deterministic ICER
det_results <- data.frame(
  Strategy = c("Hypothetical Drug & BSC", "BSC"),
  Costs = c(ce_det$costs[strategy_id == 2 & category == "total", mean(costs)],
            ce_det$costs[strategy_id == 1 & category == "total", mean(costs)]),
  QALYs = c(ce_det$qalys[strategy_id == 2, mean(qalys)],
            ce_det$qalys[strategy_id == 1, mean(qalys)])
)

# Calculate incremental values and ICER 
inc_costs <- det_results$Costs[1] - det_results$Costs[2]
inc_qalys <- det_results$QALYs[1] - det_results$QALYs[2]
icer_value <- inc_costs / inc_qalys

# Add ICER column with NA for intervention row
det_results$ICER <- c(NA, icer_value)

# Format for presentation 
det_results_psm <- det_results %>%
  mutate(
    Costs = round(Costs, 0),
    QALYs = round(QALYs, 2),
    ICER = ifelse(is.na(ICER), NA, round(ICER, 0))
  )

# The table with ICER caption
kable(det_results_psm, 
      caption = paste("ICER(£ per QALY) = ", format(round(icer_value, 0), big.mark=",")), 
      format = "html", 
      align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                           full_width = TRUE)


```

# Markov model

We code a Markov model for comparison, but first we need to prepare the data. The Markov model will need transition probabilities for each event rather than survival equations, but they will be calculated from the same data that was originally digitised. We will use the msm package to calculate transition probabilities. Other health-economic parameters are kept identical for comparison purposes. Similarly, for psa sampling we try to keep consistency where possible.

## Data preparation

Data is modified to be used in the msm package. We need to ensure that the data is in long format, and that the time of each event is sequential.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# We build a Markov model using the same data. However, we calculate transition probabilities. First, we combine the IPD data for each event and modify to be used in msm package.


mm_data <- surv_est_data %>%
  
  # Introduce AbleWalk status and time
  mutate(AbleWalk_status = 1,
         AbleWalk_time = 0) %>%
  
  # Fill sequential event times based on previous event
  mutate(
    Wheelchair_time = if_else(is.na(Wheelchair_time), AidWalk_time, Wheelchair_time),
    Bedridden_time  = if_else(is.na(Bedridden_time), Wheelchair_time, Bedridden_time),
    Death_time      = if_else(is.na(Death_time), Bedridden_time, Death_time),
    Wheelchair_time = pmax(Wheelchair_time, AidWalk_time), 
    Bedridden_time  = pmax(Bedridden_time, Wheelchair_time),
    Death_time      = pmax(Death_time, Bedridden_time)
  ) %>%
  
  # Ensure proper column order (wide format)
  dplyr::select(patient_id, strategy_name, 
         AbleWalk_status, AbleWalk_time, 
         AidWalk_status, AidWalk_time, 
         Wheelchair_status, Wheelchair_time, 
         Bedridden_status, Bedridden_time, 
         Death_status, Death_time) %>%
  
  # Pivot the *_time columns into long format
  pivot_longer(
    cols = ends_with("_time"),
    names_to = "event",
    values_to = "time"
  ) %>%
  
  # Remove the suffix to get the event name and map events to state numbers
  mutate(event = sub("_time$", "", event),
         state = case_when(
           event == "AbleWalk"   ~ 1,
           event == "AidWalk"    ~ 2,
           event == "Wheelchair" ~ 3,
           event == "Bedridden"  ~ 4,
           event == "Death"      ~ 5
         )) %>%
    # Replace NA times with the censoring time of 26 years
  mutate(time = if_else(is.na(time), 26, time)) %>%
  # For each patient and time, keep the event with the highest state value (latest state). Backwards transitions are still not allowed in this study. 
  group_by(patient_id, time) %>%
  summarize(state = max(state, na.rm = TRUE),
            strategy_name = first(strategy_name),
            .groups = "drop") %>%
  arrange(patient_id, time) %>%
  rename(subject = patient_id)

# head(mm_data)

```

## Calculate transitions matrices

We calculate transition probabilities using multistate modelling or the msm package. From the Figures it should be obvious that the msm package estimates predicted prevalence by time, which means that one can specify time t, for any interval. The transitions are governed by the Q matrices, which is a snapshot of the Markov process, and despite having a sequential progression assumption. We will observe transitions that skip health states, because of cycle length is too long, which means that these transitions are estimated. These transitions would be much closer to zero if transitions were estimated with a cycle length of one month, but we are consistent with the assumption to compare across model types. So despite not allowing certain transitions in the Q matrix, they will nonetheless be illustrated in the model structure and discussed in the manuscript.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Fetch msm package

library(msm)

# We can define Q matrices here. We need to tweak them to obtain the best fit for predicted and observed data. For example, the hypothetical drug & BSC arm had poorer prediction in comparison to observed values than for BSC alone when matrices Q were identical. It is a common issue with the msm package. In our case, it is likely caused by having same number of observations, but for the hypothetical drug they are spread over a longer time period. 

# Important. We have flexibility here to allow direct transitions to death from all health states, but this would not align with the partitioned surivival approach where patients are forced sequentially through health states. Thus, transition to death is only allowed for bedridden. 

Q_mm_bsc <- rbind(
  c(0, 0.5, 0, 0, 0), # Able to walk to Aid-required walking
  c(0, 0, 0.18, 0, 0), # Aid-required walking to Wheelchair confinement
  c(0, 0, 0, 0.18, 0), # Wheelchair confinement to Bedridden
  c(0, 0, 0, 0, 0.30), #Bedridden to death
  c(0, 0, 0, 0, 0) # Death (absorbing state)
)

Q_mm_trt <- rbind(
  c(0, 0.3, 0, 0, 0),
  c(0, 0, 0.06, 0, 0),
  c(0, 0, 0, 0.10, 0),
  c(0, 0, 0, 0, 0.40),
  c(0, 0, 0, 0, 0)
)

# We proceed to calculate for BSC

mm_data_bsc <- mm_data %>%
  filter(strategy_name == "BSC")
 
# freq_table_bsc <- statetable.msm(state, subject, data = mm_data_bsc)
# 
# 
# # Death is obsorbing, thus, not included in row.
# row_names <- c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden")
# col_names <- c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden", "Death")
# rownames(freq_table_bsc) <- row_names
# colnames(freq_table_bsc) <- col_names
# 
# # Display the frequency table using kable
# kable(freq_table_bsc, caption = "State transition frequency table - BSC", format = "html", align = 'c') %>%
#   kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
#                 full_width = TRUE, position = "center")


Q.crude_mm_bsc <- crudeinits.msm(state ~ time, subject, data = mm_data_bsc, qmatrix = Q_mm_bsc)

cav_mm_bsc <- msm(state ~ time, subject = subject, data = mm_data_bsc, qmatrix = Q_mm_bsc)

matrix_mm_bsc <- pmatrix.msm(cav_mm_bsc, t = 12/12) #Annual cycle length in model, because of the relatively long follow-up data and to align with PSM.  

plot.prevalence.msm(cav_mm_bsc, mintime = 0, maxtime = 17) # Max time is 17 years

matrix_mm_bsc <- matrix(matrix_mm_bsc, nrow = 5, ncol = 5, byrow = FALSE)

state_labels <- c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden", "Death")

colnames(matrix_mm_bsc) <- state_labels
rownames(matrix_mm_bsc) <- state_labels

kable(matrix_mm_bsc, caption = "Transition probabilities for BSC", format = "html", align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), full_width = TRUE, position = "center")

# Lastly, we calculate transition probabilities for 

mm_data_trt <- mm_data %>%
  filter(strategy_name == "Hypothetical Drug & BSC")

# freq_table_trt <- statetable.msm(state, subject, data = mm_data_trt)
# 
# row_names <- c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden")
# col_names <- c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden", "Death")
# rownames(freq_table_trt) <- row_names
# colnames(freq_table_trt) <- col_names
# 
# kable(freq_table_trt, caption = "State transition frequency table - Hypothetical Drug & BSC", format = "html", align = 'c') %>%
#   kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
#                 full_width = TRUE, position = "center")


Q.crude_mm_trt <- crudeinits.msm(state ~ time, subject, data = mm_data_trt, qmatrix = Q_mm_trt)

cav_mm_trt <- msm(state ~ time, subject = subject, data = mm_data_trt, qmatrix = Q_mm_trt)

matrix_mm_trt <- pmatrix.msm(cav_mm_trt, t = 12/12)

plot.prevalence.msm(cav_mm_trt, mintime = 0, maxtime = 26) # Max time is 26 years

matrix_mm_trt <- matrix(matrix_mm_trt, nrow = 5, ncol = 5, byrow = FALSE)
rownames(matrix_mm_trt) <- colnames(matrix_mm_trt) <- state_labels

kable(matrix_mm_trt, caption = "Transition probabilities for Hypothetical Drug & BSC", format = "html", align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"), full_width = TRUE, position = "center")

```

## Define model parameters

We define model parameters, and fetch those already defined in PSM.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Sourcing existing model parameters

mm_costs <- costs # cost data

mm_drug <- Drug # drug cost

mm_utilities <- utilities # utility data

mm_strategies <- c(strategies$strategy_name[1], strategies$strategy_name[2]) # Intervention names

mm_rr_trt_mod_e <- rr_trt_mod_e # Relative risk treament modifier for events

mm_p_UD <- p_UD # Probability of urinary or bladder disorders
mm_p_HD <- p_HD # Probability hypotension disorders
mm_p_BD <- p_HD # Probability bowel disorders

mm_du_UD <- du_UD # Disutility urinary or bladder disorders
mm_du_HD <- du_HD # Disutility hypotension disorders
mm_du_BD <- du_BD # Disutility bowel disorders

mm_disutilities <- -c(mm_p_UD * mm_du_UD + mm_p_HD * mm_du_HD + mm_p_BD * mm_du_BD)
mm_disutilities_trt <- -c(mm_p_UD * mm_du_UD * mm_rr_trt_mod_e + mm_p_HD * mm_du_HD * mm_rr_trt_mod_e + mm_p_BD * mm_du_BD * mm_rr_trt_mod_e)

# Markov Model parameters

mm_n_cycles <- 32 # Number of annual cycles in the model 1-32 (to match the PSM 0-31)

mm_v_names_states <- c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden", "Death")

mm_n_states <- length(mm_v_names_states) # Number of states

mm_d_c <-0.035 # discount rate for costs
mm_d_e <- 0.035 # discount rate for effects

# Costs (we use UMSARS IV as a proxy for event costs)

mm_c_W <- mm_costs$Total[mm_costs$UMSARS == "UMSARS_IV 1 + 2"] %>%
  round(2)
mm_c_Aw <- mm_costs$Total[mm_costs$UMSARS == "UMSARS_IV 3"] %>%
  round(2)
mm_c_Wc <- mm_costs$Total[mm_costs$UMSARS == "UMSARS_IV 4"] %>%
  round(2)
mm_c_B <- mm_costs$Total[mm_costs$UMSARS == "UMSARS_IV 5"] %>%
  round(2)
mm_c_D <- 0

# Utilities (we use UMSARS IV as a proxy for event utilities)  

mm_u_W <- mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "1 + 2"] %>%
  round(2)
mm_u_Aw <- mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "3"] %>%
  round(2)
mm_u_Wc <- mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "4"] %>%
  round(2)
mm_u_B <- mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "5"] %>%
  round(2)
mm_u_D <- 0

# Discount weights 

mm_d_wc <- 1 / (1 + mm_d_c)^(0:(mm_n_cycles-1))
mm_d_we <- 1 / (1 + mm_d_e)^(0:(mm_n_cycles-1))


```

## Markov traces

We need to set up an empty Markov trace and set initial distribution of patients.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Create a Markov trace for BSC

mm_TR_bsc <- matrix(data = NA, nrow = mm_n_cycles, ncol = mm_n_states, dimnames = list(1:mm_n_cycles, mm_v_names_states))

# Set initial distribution

mm_TR_bsc[1, ] <- c(1, 0, 0, 0, 0) # Start in Able to walk state

#head(mm_TR_bsc)

# We also create Markov trace for Hypothetical Drug & BSC

mm_TR_trt <- matrix(data = NA, nrow = mm_n_cycles, ncol = mm_n_states, dimnames = list(1:mm_n_cycles, mm_v_names_states))

# Set initial distribution
mm_TR_trt[1, ] <- c(1, 0, 0, 0, 0) # Start in Able to walk state

```

## Run Markov traces

We make the calculations of state occupancy.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Run the Markov model for BSC
for (t in 2:mm_n_cycles) {
  mm_TR_bsc[t, ] <- mm_TR_bsc[t - 1, ] %*% matrix_mm_bsc
}

#head(mm_TR_bsc)

# Run the Markov model for Hypothetical Drug & BSC
for (t in 2:mm_n_cycles) {
  mm_TR_trt[t, ] <- mm_TR_trt[t - 1, ] %*% matrix_mm_trt
}


# Plot health state occupancy 

## Combine data into data frames 


df_TR_bsc <- as.data.frame(mm_TR_bsc)
df_TR_bsc$Cycle <- 0:(nrow(df_TR_bsc)-1)  # Changed to align the starting point with the PSM
df_TR_bsc$Strategy <- mm_strategies[1]

df_TR_trt <- as.data.frame(mm_TR_trt)
df_TR_trt$Cycle <- 0:(nrow(df_TR_trt)-1)
df_TR_trt$Strategy <- mm_strategies[2]

df_TR_strat <- rbind(df_TR_bsc, df_TR_trt)
df_TR_strat <- pivot_longer(df_TR_strat, cols = mm_v_names_states,
              names_to = "HealthState", values_to = "Proportion")
df_TR_strat$HealthState <- factor(df_TR_strat$HealthState, levels = rev(mm_v_names_states))

# Plot health state occupancy for BSC and Hypothetical Drug & BSC
ggplot(df_TR_strat, aes(x = Cycle, y = Proportion, fill = HealthState)) +
  geom_area(alpha = 0.65) +
  facet_wrap(~Strategy, ncol = 2) +
  labs(title = "Markov Model – Health State Occupancy Over Time",
     x = "Cycle",
     y = "Proportion in State") +
  scale_fill_manual(name = "",
          values = c("Able to walk" = "#74c476", 
                 "Aid-required walking" = "#a1d99b", 
                 "Wheelchair confinement" = "#fd8d3c", 
                 "Bedridden" = "#e34a33",
                 "Death" = "#969696"),
          breaks = c("Able to walk", "Aid-required walking", "Wheelchair confinement", "Bedridden", "Death")) +
  theme_minimal() +
  theme(legend.position = "bottom",
    plot.title = element_text(hjust = 0.5))

```

## We calculate costs and QALYs

We run the deterministic analysis for both strategies and calculate costs and QALYs.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Calculate costs and QALYs for BSC

## BSC

v_c_bsc <- c("Able to walk" = mm_c_W, 
                 "Aid-required walking" = mm_c_Aw, 
                 "Wheelchair confinement" = mm_c_Wc, 
                 "Bedridden" = mm_c_B, 
                 "Death" = mm_c_D)

v_u_bsc <- c("Able to walk" = mm_u_W + mm_disutilities, # Add disutilities to utilities as disutility is inherently negative 
                 "Aid-required walking" = mm_u_Aw + mm_disutilities, 
                 "Wheelchair confinement" = mm_u_Wc + mm_disutilities, 
                 "Bedridden" = mm_u_B + mm_disutilities, 
                 "Death" = mm_u_D)

## Hypothetical Drug & BSC

v_c_trt <- c("Able to walk" = mm_c_W + mm_drug, 
                 "Aid-required walking" = mm_c_Aw + mm_drug, 
                 "Wheelchair confinement" = mm_c_Wc + mm_drug, 
                 "Bedridden" = mm_c_B, 
                 "Death" = mm_c_D)

v_u_trt <- c("Able to walk" = mm_u_W + mm_disutilities_trt,
                 "Aid-required walking" = mm_u_Aw + mm_disutilities_trt, 
                 "Wheelchair confinement" = mm_u_Wc + mm_disutilities_trt, 
                 "Bedridden" = mm_u_B + mm_disutilities, 
                 "Death" = mm_u_D)

# Multiply vectors by the Markov trace to get costs and QALYs

v_E_BSC <- (mm_TR_bsc %*% v_u_bsc)
v_C_BSC <- (mm_TR_bsc %*% v_c_bsc)

v_E_trt <- (mm_TR_trt %*% v_u_trt)
v_C_trt <- (mm_TR_trt %*% v_c_trt)

# Discount weights

v_E_BSC_dis <- sum(v_E_BSC * mm_d_we) 
v_C_BSC_dis <- sum(v_C_BSC * mm_d_wc)

v_E_trt_dis <- sum(v_E_trt * mm_d_we)
v_C_trt_dis <- sum(v_C_trt * mm_d_wc)

# Results 

  results_det <- c(
    "Costs_BSC" = v_C_BSC_dis,
    "Costs_trt" = v_C_trt_dis,
    "QALYs_BSC" = v_E_BSC_dis,
    "QALYs_trt" = v_E_trt_dis,
    "ICER" = (v_C_trt_dis - v_C_BSC_dis) / (v_E_trt_dis - v_E_BSC_dis)
  )

# Format results for presentation

  results_det <- data.frame(
    Strategy = c("Hypothetical Drug & BSC", "BSC"),
    Costs = c(results_det["Costs_trt"], results_det["Costs_BSC"]),
    QALYs = c(results_det["QALYs_trt"], results_det["QALYs_BSC"]),
    ICER = c(NA, results_det["ICER"])
  )
  
rownames(results_det) <- NULL

mm_results_det <- results_det %>%
  mutate(
    Costs = round(Costs, 0),
    QALYs = round(QALYs, 2),
    ICER = ifelse(is.na(ICER), NA, round(ICER, 0))
  )

# The table with ICER caption

kable(mm_results_det, 
      caption = paste("ICER(£ per QALY) = ", format(round(mm_results_det$ICER[2], 2), big.mark=",")), 
      format = "html", 
      align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                           full_width = TRUE)

 
    
```

## Generate PSA inputs

Assign distributions to the parameters varied in PSA.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Setting up the function to run sampling 

mm_n_sim <- n_samples # Number of samples. Same as for PSM. 

f_gen_psa <- function (mm_n_sim = 500, mm_drug = 12000) {
  
  # Health state costs
  
# Health state costs - ensure identical gamma parameters as PSM
mm_c_W_samples <- rgamma(mm_n_sim, 
               shape = (costs$Total[costs$UMSARS == "UMSARS_IV 1 + 2"])^2 / 
                       (costs$StandardError[costs$UMSARS == "UMSARS_IV 1 + 2"])^2,
               scale = (costs$StandardError[costs$UMSARS == "UMSARS_IV 1 + 2"])^2 / 
                       (costs$Total[costs$UMSARS == "UMSARS_IV 1 + 2"]))

mm_c_Aw_samples <- rgamma(mm_n_sim, 
               shape = (costs$Total[costs$UMSARS == "UMSARS_IV 3"])^2 / 
                       (costs$StandardError[costs$UMSARS == "UMSARS_IV 3"])^2,
               scale = (costs$StandardError[costs$UMSARS == "UMSARS_IV 3"])^2 / 
                       (costs$Total[costs$UMSARS == "UMSARS_IV 3"]))

mm_c_Wc_samples <- rgamma(mm_n_sim, 
               shape = (costs$Total[costs$UMSARS == "UMSARS_IV 4"])^2 / 
                       (costs$StandardError[costs$UMSARS == "UMSARS_IV 4"])^2,
               scale = (costs$StandardError[costs$UMSARS == "UMSARS_IV 4"])^2 / 
                       (costs$Total[costs$UMSARS == "UMSARS_IV 4"]))

mm_c_B_samples <- rgamma(mm_n_sim,
               shape = (costs$Total[costs$UMSARS == "UMSARS_IV 5"])^2 / 
                       (costs$StandardError[costs$UMSARS == "UMSARS_IV 5"])^2,
               scale = (costs$StandardError[costs$UMSARS == "UMSARS_IV 5"])^2 / 
                       (costs$Total[costs$UMSARS == "UMSARS_IV 5"]))

mm_c_D_samples <- rep(0, mm_n_sim)
  
  # Drug costs
  
  mm_c_drug_samples <- rep(mm_drug, mm_n_sim)
  
  # Health state utilities
  
  ## We need to define parameters for utilities according to the distribution.
  
sample_beta <- function(n, mean, sd) {
  # Calculate alpha and beta parameters
  var <- sd^2
  alpha <- mean * (mean * (1 - mean) / var - 1)
  beta <- (1 - mean) * (mean * (1 - mean) / var - 1)
  # Handle cases where parameters are invalid
  if(alpha <= 0 || beta <= 0) {
    return(rep(mean, n))  # Return fixed value if parameters invalid
  } else {
    return(rbeta(n, shape1 = alpha, shape2 = beta))
  }
}

# Sample utilities for BSC arm (with disutilities)

mm_u_W_samples <- sample_beta(mm_n_sim, 
                             mean = mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "1 + 2"] + mm_disutilities, 
                             sd = mm_utilities$Standard_Deviation[mm_utilities$UMSARS_IV == "1 + 2"])

mm_u_Aw_samples <- sample_beta(mm_n_sim, 
                              mean = mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "3"] + mm_disutilities, 
                              sd = mm_utilities$Standard_Deviation[mm_utilities$UMSARS_IV == "3"])

mm_u_Wc_samples <- sample_beta(mm_n_sim, 
                              mean = mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "4"] + mm_disutilities, 
                              sd = mm_utilities$Standard_Deviation[mm_utilities$UMSARS_IV == "4"])

mm_u_B_samples <- sample_beta(mm_n_sim, 
                             mean = mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "5"] + mm_disutilities, 
                             sd = mm_utilities$Standard_Deviation[mm_utilities$UMSARS_IV == "5"])

# Sample utilities for treatment arm (with treatment-modified disutilities)

mm_u_W_trt_samples <- sample_beta(mm_n_sim, 
                                 mean = mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "1 + 2"] + mm_disutilities_trt, 
                                 sd = mm_utilities$Standard_Deviation[mm_utilities$UMSARS_IV == "1 + 2"])

mm_u_Aw_trt_samples <- sample_beta(mm_n_sim, 
                                  mean = mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "3"] + mm_disutilities_trt, 
                                  sd = mm_utilities$Standard_Deviation[mm_utilities$UMSARS_IV == "3"])

mm_u_Wc_trt_samples <- sample_beta(mm_n_sim, 
                                  mean = mm_utilities$Mean_Index_Score[mm_utilities$UMSARS_IV == "4"] + mm_disutilities_trt, 
                                  sd = mm_utilities$Standard_Deviation[mm_utilities$UMSARS_IV == "4"])

# For Bedridden state there is no treatment modification 

mm_u_B_trt_samples <- mm_u_B_samples  # Same as BSC

# Death utilities
mm_u_D_samples <- rep(0, mm_n_sim)
  
# For transition matrices. We want to use dirichlet distribution to sample transition probabilities to make sure rows sum to 1. 

  # Sample transition probabilities using Dirichlet distribution using MCMCpack package
  # For transition matrices, create arrays to store all samples
  mm_P_bsc_samples <- array(NA, dim = c(mm_n_sim, mm_n_states, mm_n_states),
                           dimnames = list(NULL, mm_v_names_states, mm_v_names_states))
  
  mm_P_trt_samples <- array(NA, dim = c(mm_n_sim, mm_n_states, mm_n_states),
                           dimnames = list(NULL, mm_v_names_states, mm_v_names_states))
  
  # Sample transition probabilities for each row of transition matrix
  for(state in 1:mm_n_states) {
    # Transition probabilities for BSC
    alpha_bsc <- matrix_mm_bsc[state,] * n_used  # Concentration parameter controls variance. From a Bayesian perspective, this is the prior information e.g., prior observations. Thus, we use n_used = 230.
    sampled_probs_bsc <- rdirichlet(mm_n_sim, alpha_bsc)
    for(i in 1:mm_n_sim) {
      mm_P_bsc_samples[i, state, ] <- sampled_probs_bsc[i,]
    }
    
    # Transition probabilities for treatment arm
    alpha_trt <- matrix_mm_trt[state,] * n_used
    sampled_probs_trt <- rdirichlet(mm_n_sim, alpha_trt)
    for(i in 1:mm_n_sim) {
      mm_P_trt_samples[i, state, ] <- sampled_probs_trt[i,]
    }
  }

  # Return all sampled parameters
  
  return(list(
  sample_id = 1:mm_n_sim,
  mm_c_W_samples = mm_c_W_samples,
  mm_c_Aw_samples = mm_c_Aw_samples,
  mm_c_Wc_samples = mm_c_Wc_samples,
  mm_c_B_samples = mm_c_B_samples,
  mm_c_D_samples = mm_c_D_samples,
  mm_c_drug_samples = mm_c_drug_samples,
  mm_u_W_samples = mm_u_W_samples,
  mm_u_Aw_samples = mm_u_Aw_samples,
  mm_u_Wc_samples = mm_u_Wc_samples,
  mm_u_B_samples = mm_u_B_samples,
  mm_u_D_samples = mm_u_D_samples,
  mm_u_W_trt_samples = mm_u_W_trt_samples,
  mm_u_Aw_trt_samples = mm_u_Aw_trt_samples,
  mm_u_Wc_trt_samples = mm_u_Wc_trt_samples,
  mm_u_B_trt_samples = mm_u_B_trt_samples,
  mm_P_bsc_samples = mm_P_bsc_samples,
  mm_P_trt_samples = mm_P_trt_samples,
  mm_d_we = mm_d_we,
  mm_d_wc = mm_d_wc
))
} # End of function

# Run PSA 

df_psa <- f_gen_psa(mm_n_sim, mm_drug)

```

## We run probabilistic sensitivity analysis

We run the loop the sampled parameters through the Markov model.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

f_MM_MSA <- function (params) {
  
  with(as.list(params), {
    
##################### MARKOV TRACES ########################    
    
    # Create empty Markov trace for BSC
    mm_TR_bsc_samples <- matrix(data = NA, nrow = mm_n_cycles, ncol = mm_n_states, dimnames = list(1:mm_n_cycles, mm_v_names_states))
    
    # Set initial distribution
    mm_TR_bsc_samples[1, ] <- c(1, 0, 0, 0, 0) # Start in Able to walk state
    
    # Run the Markov model for BSC
    for (t in 2:mm_n_cycles) {
      mm_TR_bsc_samples[t, ] <- mm_TR_bsc_samples[t - 1, ] %*% params$mm_P_bsc_samples[params$sample_id, , ]
    }
    
    # Create empty Markov trace for Hypothetical Drug & BSC
    
    mm_TR_trt_samples <- matrix(data = NA, nrow = mm_n_cycles, ncol = mm_n_states, dimnames = list(1:mm_n_cycles, mm_v_names_states))
    
    # Set initial distribution
    mm_TR_trt_samples[1, ] <- c(1, 0, 0, 0, 0) # Start in Able to walk state
    
    # Run the Markov model for Hypothetical Drug & BSC
    for (t in 2:mm_n_cycles) {
      mm_TR_trt_samples[t, ] <- mm_TR_trt_samples[t - 1, ] %*% params$mm_P_trt_samples[params$sample_id, , ]
    }
    
##################### COSTS ########################
    
    # Calculate costs for BSC
    v_c_bsc_samples <- c("Able to walk" = params$mm_c_W_samples[params$sample_id], 
                         "Aid-required walking" = params$mm_c_Aw_samples[params$sample_id], 
                         "Wheelchair confinement" = params$mm_c_Wc_samples[params$sample_id], 
                         "Bedridden" = params$mm_c_B_samples[params$sample_id], 
                         "Death" = params$mm_c_D_samples[params$sample_id])
    
    # Calculate costs for Hypothetical Drug & BSC
    v_c_trt_samples <- c("Able to walk" = params$mm_c_W_samples[params$sample_id] + params$mm_c_drug_samples[params$sample_id], 
                         "Aid-required walking" = params$mm_c_Aw_samples[params$sample_id] + params$mm_c_drug_samples[params$sample_id], 
                         "Wheelchair confinement" = params$mm_c_Wc_samples[params$sample_id] + params$mm_c_drug_samples[params$sample_id], 
                         "Bedridden" = params$mm_c_B_samples[params$sample_id], 
                         "Death" = params$mm_c_D_samples[params$sample_id])
    
    # Multiply vectors by the Markov trace to get costs
    v_C_BSC_samples <- (mm_TR_bsc_samples %*% v_c_bsc_samples)
    v_C_trt_samples <- (mm_TR_trt_samples %*% v_c_trt_samples)
    
##################### QALYs ########################
    
    # Calculate QALYs for BSC
    v_u_bsc_samples <- c("Able to walk" = params$mm_u_W_samples[params$sample_id], 
                         "Aid-required walking" = params$mm_u_Aw_samples[params$sample_id], 
                         "Wheelchair confinement" = params$mm_u_Wc_samples[params$sample_id], 
                         "Bedridden" = params$mm_u_B_samples[params$sample_id], 
                         "Death" = params$mm_u_D_samples[params$sample_id])
    
    # Calculate QALYs for Hypothetical Drug & BSC
    v_u_trt_samples <- c("Able to walk" = params$mm_u_W_trt_samples[params$sample_id], 
                         "Aid-required walking" = params$mm_u_Aw_trt_samples[params$sample_id], 
                         "Wheelchair confinement" = params$mm_u_Wc_trt_samples[params$sample_id], 
                         "Bedridden" = params$mm_u_B_trt_samples[params$sample_id], 
                         "Death" = params$mm_u_D_samples[params$sample_id])
    
    # Multiply vectors by the Markov trace to get QALYs
    v_E_BSC_samples <- (mm_TR_bsc_samples %*% v_u_bsc_samples)
    v_E_trt_samples <- (mm_TR_trt_samples %*% v_u_trt_samples)
    
##################### DISCOUNTING ########################
    # Discount weights
    v_E_BSC_dis_samples <- sum(v_E_BSC_samples * params$mm_d_we)
    v_C_BSC_dis_samples <- sum(v_C_BSC_samples * params$mm_d_wc)
    
    v_E_trt_dis_samples <- sum(v_E_trt_samples * params$mm_d_we)
    v_C_trt_dis_samples <- sum(v_C_trt_samples * params$mm_d_wc)
    
##################### RESULTS ########################
    
    # PSA results
    
    results_psa <- c(
      "Costs_BSC" = v_C_BSC_dis_samples,
      "Costs_trt" = v_C_trt_dis_samples,
      "QALYs_BSC" = v_E_BSC_dis_samples,
      "QALYs_trt" = v_E_trt_dis_samples,
      "ICER" = (v_C_trt_dis_samples - v_C_BSC_dis_samples) / (v_E_trt_dis_samples - v_E_BSC_dis_samples)
    )
    
    # Return results
    
    return(results_psa)
    
  }) # End function
    
} # End with

```

## PSA results

We provide an ICER table of results, which is the average of our simulations.

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}
  
# Run the PSA
m_out <- matrix(NaN, nrow = mm_n_sim, ncol = 5, 
               dimnames = list(1:mm_n_sim, 
                              c("Costs_BSC", "Costs_trt", "QALYs_BSC", "QALYs_trt", "ICER")))

for (i in 1:mm_n_sim) {
  # Create a copy of the parameter list but with the specific sample_id
  params_i <- df_psa
  params_i$sample_id <- i
  
  # Pass the modified list to the function
  m_out[i, ] <- f_MM_MSA(params = params_i)
}

# Convert to data frame

df_out <- as.data.frame(m_out)

# Calculate means for each column
mean_costs_bsc <- mean(df_out$Costs_BSC)
mean_costs_trt <- mean(df_out$Costs_trt)
mean_qalys_bsc <- mean(df_out$QALYs_BSC)
mean_qalys_trt <- mean(df_out$QALYs_trt)

# Calculate ICER based on means
mean_icer <- (mean_costs_trt - mean_costs_bsc) / (mean_qalys_trt - mean_qalys_bsc)

# Create summary table
mm_icer_table_psa <- data.frame(
  Strategy = c("Hypothetical Drug & BSC", "BSC"),
  Costs = c(mean_costs_trt, mean_costs_bsc),
  QALYs = c(mean_qalys_trt, mean_qalys_bsc),
  ICER = c(NA, mean_icer)
)

# Format the values
mm_icer_table_psa$Costs <- round(mm_icer_table_psa$Costs, 0)
mm_icer_table_psa$QALYs <- round(mm_icer_table_psa$QALYs, 2)
mm_icer_table_psa$ICER <- ifelse(is.na(mm_icer_table_psa$ICER), NA, round(mm_icer_table_psa$ICER, 0))

# Create a nice table with kable
kable(mm_icer_table_psa, 
      caption = paste("ICER(£ per QALY) = ", format(round(mean_icer, 0), big.mark=",")), 
      format = "html", 
      align = 'c') %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                            full_width = TRUE)

```

## Cost-effectiveness plane

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Calculate incremental cost and QALYs
df_out$inc_C <- df_out$Costs_trt - df_out$Costs_BSC
df_out$inc_E <- df_out$QALYs_trt - df_out$QALYs_BSC

# Calculate symmetric limits around zero
max_inc_E <- max(abs(df_out$inc_E))
max_inc_C <- max(abs(df_out$inc_C))

ggplot(df_out, aes(x = inc_E, y = inc_C)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_abline(intercept = 0, slope = 30000, linetype = "dotted", color = "red") +
  annotate("text", x = -max_inc_E * 1, y = max_inc_C * -0.5, label = "£ 30,000 WTP threshold", color = "red", hjust = 0, vjust = 1, size = 5) +
  labs(
    title = "Cost-effectiveness plane",
    x = "Incremental QALYs",
    y = "Incremental Costs"
  ) +
  scale_x_continuous(
    labels = function(x) format(round(x, 2), scientific = FALSE),
    breaks = scales::pretty_breaks(n = 5)
  ) +
  scale_y_continuous(
    labels = function(x) paste0("£ ", format(round(x, 0), big.mark = ",", scientific = FALSE)),
    limits = c(-max_inc_C, max_inc_C),
    breaks = scales::pretty_breaks(n = 10)
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.title = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 14),
    legend.text = element_text(size = 14),
    legend.position = "bottom"
  )

```

## Cost-effectiveness acceptability curve

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Define the willingness-to-pay (WTP) thresholds. We use same range as for PSM.

willingness_to_pay <- seq(0, 200000, by = 500)
df_ceac <- data.frame(
  WTP = willingness_to_pay,
  Probability = NA
)

# Calculate probability that treatment is cost-effective at each WTP
for (i in 1:length(willingness_to_pay)) {
  wtp <- willingness_to_pay[i]
  # Net monetary benefit = WTP * QALY gain - Cost increase
  nmb <- wtp * df_out$inc_E - df_out$inc_C
  # Probability = proportion of simulations with positive NMB
  df_ceac$Probability[i] <- mean(nmb > 0)
}

# CEAC plot
ggplot(df_ceac, aes(x = WTP, y = Probability)) +
  geom_line(linewidth = 0.5, color = "red") +  # Using linewidth instead of size
  labs(
    title = "Cost-effectiveness Acceptability Curve",
    x = "Willingness-to-Pay Threshold (£)",
    y = "Probability of Cost-effectiveness"
  ) +
  scale_x_continuous(
    labels = function(x) paste0("£ ", format(round(x, 0), big.mark = ",")),
    limits = c(0, max(willingness_to_pay)),
    breaks = seq(0, 200000, 50000)
  ) +
  scale_y_continuous(
    labels = function(x) format(round(x, 2), scientific = FALSE),
    limits = c(0, 1),
    breaks = seq(0, 1, by = 0.1)
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 10),
    legend.position = "none"  # No legend needed for single line
  )
```

## Expected value of perfect information on the individual level

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Calculate EVPI
evpi <- function(df_out, wtp) {
  # Calculate net monetary benefit for each simulation
  nmb_trt <- wtp * df_out$QALYs_trt - df_out$Costs_trt
  nmb_bsc <- wtp * df_out$QALYs_BSC - df_out$Costs_BSC
  
  # Decision with current information: choose strategy with highest expected NMB
  mean_nmb_trt <- mean(nmb_trt)
  mean_nmb_bsc <- mean(nmb_bsc)
  decision_current <- ifelse(mean_nmb_trt > mean_nmb_bsc, "trt", "bsc")
  
  # Expected NMB with current decision
  exp_nmb_current <- ifelse(decision_current == "trt", mean_nmb_trt, mean_nmb_bsc)
  
  # Calculate optimal strategy for each simulation
  optimal_strategy <- ifelse(nmb_trt > nmb_bsc, "trt", "bsc")
  
  # Calculate maximum NMB for each simulation (with perfect information)
  max_nmb <- ifelse(optimal_strategy == "trt", nmb_trt, nmb_bsc)
  
  # EVPI is the difference between expected NMB with perfect information and with current information
  evpi_value <- mean(max_nmb) - exp_nmb_current
  
  return(evpi_value)
}

# Calculate EVPI using the same WTP vector as CEAC
evpi_values <- sapply(willingness_to_pay, function(wtp) evpi(df_out, wtp))

# Dataframe for plotting
evpi_data <- data.frame(
  wtp = willingness_to_pay,
  evpi = evpi_values
)

# Plot EVPI curve
ggplot(evpi_data, aes(x = wtp, y = evpi)) +
  geom_line(linewidth = 0.5, color = "black") +
  labs(
    title = "Expected Value of Perfect Information",
    x = "Willingness-to-Pay Threshold (£)",
    y = "EVPI (£)"
  ) +
  scale_x_continuous(
    labels = function(x) paste0("£ ", format(round(x, 0), big.mark = ",")),
    limits = c(0, max(willingness_to_pay)),
    breaks = seq(0, 200000, 50000)
  ) +
  scale_y_continuous(
    labels = function(x) paste0("£ ", format(round(x, 0), big.mark = ",")),
    breaks = scales::pretty_breaks(n = 8)
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 10)
  )

```

# Visuals for the report

In this section we seek to combine the plots for illustration purposes.

## State Occupancy

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Rename columns in df_TR_strat to match PSM format

markov_states <- df_TR_strat %>% #Markov trace
  rename(t = Cycle, 
         prob = Proportion,
         state_name = HealthState,
         strategy = Strategy) %>% # Important: rename Strategy to match PSM's lowercase
  mutate(model = "Markov Model", #Model identifier
         state_id = case_when(  # Add state_id to match PSM's structure
           state_name == "Able to walk" ~ 1,
           state_name == "Aid-required walking" ~ 2,
           state_name == "Wheelchair confinement" ~ 3,
           state_name == "Bedridden" ~ 4,
           state_name == "Death" ~ 5
         ),
         strategy_id = case_when( # Add strategy_id to match PSM's structure
           strategy == "BSC" ~ 1,
           strategy == "Hypothetical Drug & BSC" ~ 2
         ))

# Prepare PSM data with model identifier
psm_states <- stateprobs_psm_agg %>%
  mutate(model = "Partitioned Survival Model")

# Ensure both datasets have matching column names and orders before combining
common_columns <- c("state_id", "t", "strategy_id", "prob", "state_name", "strategy", "model")

# Select and order columns consistently for both data frames
markov_states <- markov_states %>% dplyr::select(all_of(common_columns))
psm_states <- psm_states %>% dplyr::select(all_of(common_columns))

# Then combine
combined_occupancy <- bind_rows(psm_states, markov_states)

# Create comparison plot with models side-by-side
ggplot(combined_occupancy, aes(x = t, y = prob, fill = state_name)) +
  geom_area(alpha = 0.7) +
  facet_grid(model ~ strategy, scales = "free_y") +
  labs(title = "Comparison of Health State Occupancy",
       x = "Time (Years)",
       y = "Proportion in State") +
  scale_fill_manual(name = "",
                   values = c("Able to walk" = "#74c476", 
                              "Aid-required walking" = "#a1d99b", 
                              "Wheelchair confinement" = "#fd8d3c", 
                              "Bedridden" = "#e34a33",
                              "Death" = "#969696"),
                   breaks = c("Able to walk", "Aid-required walking", 
                             "Wheelchair confinement", "Bedridden", "Death")) +
  theme_minimal() +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
        strip.text = element_text(size = 12, face = "bold"),
        strip.background = element_rect(fill = "lightgray", color = NA),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10))

```

## Alternative plot for Markov traces

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Comparison plot with state trajectories shown as lines
ggplot(combined_occupancy, aes(x = t, y = prob * 100, color = state_name, linetype = model)) +
  geom_line(linewidth = 0.5) +
  facet_wrap(~strategy, ncol = 2) +
  labs(title = "Comparison of Health State Occupancy",
       x = "Time (Years)",
       y = "Percentage in State (%)") +
  scale_color_manual(name = "",
                    values = c("Able to walk" = "#74c476", 
                              "Aid-required walking" = "#a1d99b", 
                              "Wheelchair confinement" = "#fd8d3c", 
                              "Bedridden" = "#e34a33",
                              "Death" = "#969696"),
                    breaks = c("Able to walk", "Aid-required walking", 
                              "Wheelchair confinement", "Bedridden", "Death")) +
  scale_linetype_manual(name = "",
                       values = c("Partitioned Survival Model" = "solid", "Markov Model" = "dashed")) +
  scale_y_continuous(
    limits = c(0, 100),
    breaks = seq(0, 100, by = 20)) +
  theme_minimal() +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
        strip.text = element_text(size = 10, face = "bold"),
        legend.box = "vertical",
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10))

```

## ICER tables

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE}

# Name tables for comparison

psm_det_results <- det_results_psm %>% 
  mutate(Model = "Partitioned Survival Model", 
         Analysis = "Deterministic")

# PSM probabilistic
psm_psa_results <- icer_table_psa_psm %>% 
  mutate(Model = "Partitioned Survival Model", 
         Analysis = "Probabilistic")
  
# Markov deterministic
mm_det_results <- mm_results_det %>% 
  mutate(Model = "Markov Model", 
         Analysis = "Deterministic")
  
# Markov probabilistic
mm_psa_results <- mm_icer_table_psa %>% 
  mutate(Model = "Markov Model", 
         Analysis = "Probabilistic")

# Combine all tables
combined_results <- bind_rows(
  psm_det_results,
  psm_psa_results,
  mm_det_results,
  mm_psa_results
 )%>%
  mutate( # Keep similar rounding
    Costs = round(Costs, 0),
    QALYs = round(QALYs, 2),
    ICER = ifelse(is.na(ICER), NA, round(ICER, 0))
  ) %>%
  mutate(
    Costs = paste0("£", format(Costs, big.mark = ",", scientific = FALSE)),
    QALYs = format(QALYs, nsmall = 2),
    ICER = ifelse(is.na(ICER), "NA", 
                 paste0("£", format(ICER, big.mark = ",", scientific = FALSE)))
  )

# Combined Table

combined_results %>%
  dplyr::select(Model, Analysis, Strategy, Costs, QALYs, ICER) %>%
  kable(caption = "Comparison of Cost-Effectiveness Results Between Models", 
        align = c("l", "l", "l", "r", "r", "r")) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = TRUE) %>%
  kableExtra::collapse_rows(columns = 1:2, valign = "middle")

```

## Cost-effectiveness plane

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Data frame with PSM results
psm_results <- data.frame(
  inc_E = cea_pw_out$delta$ie,
  inc_C = cea_pw_out$delta$ic,
  model = "Partitioned Survival Model"
)

# Data frame with Markov results
markov_results <- data.frame(
  inc_E = df_out$inc_E,
  inc_C = df_out$inc_C,
  model = "Markov Model"
)

# Combine results
combined_simulations <- rbind(psm_results, markov_results)

# Calculate symmetric limits around zero for both models
max_inc_E <- max(abs(combined_simulations$inc_E))
max_inc_C <- max(abs(combined_simulations$inc_C))

# Combined cost-effectiveness plane

ggplot(combined_simulations, aes(x = inc_E, y = inc_C, color = model, shape = model)) +
  geom_point(alpha = 0.6, size = 1.2) +
  # Reference lines 
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
  # WTP threshold
  geom_abline(intercept = 0, slope = 30000, linetype = "dotted", color = "#E41A1C", linewidth = 1) +
  annotate("text", x = max_inc_E * -0.9, y = -max_inc_C * 0.9, 
           label = "£30,000 WTP threshold", color = "#E41A1C", hjust = 0, 
           fontface = "plain", size = 2.5) +
  # Labels
  labs(
    title = "Cost-effectiveness Plane: PSM vs Markov Model",
    x = "Incremental QALYs",
    y = "Incremental Costs (£)"
  ) +
  scale_x_continuous(
    labels = function(x) format(round(x, 2), scientific = FALSE),
    breaks = scales::pretty_breaks(n = 6)
  ) +
  scale_y_continuous(
    labels = function(x) paste0("£", format(round(x, 0), big.mark = ",", scientific = FALSE)),
    limits = c(-max_inc_C, max_inc_C),
    breaks = scales::pretty_breaks(n = 8)
  ) +
  scale_color_manual(
    values = c("Partitioned Survival Model" = "#3366cc", "Markov Model" = "#cc3366"),
    name = ""
  ) +
  scale_shape_manual(
    values = c("Partitioned Survival Model" = 16, "Markov Model" = 17),  # Circle and triangle
    name = ""
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 10),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray95"),
    axis.line = element_line(color = "gray50")
  )

```

## Cost-effectiveness acceptability curve

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Combine CEACs into one data frame

# For PSM
psm_ceac <- cea_pw_out$ceac %>%
  dplyr::select(k, prob) %>%
  rename(WTP = k, Probability = prob) %>% # Rename to match Markov format
  mutate(Model = "Partitioned Survival Model")

# For Markov 
markov_ceac <- df_ceac %>%
  mutate(Model = "Markov Model")

# Combine the datasets
combined_ceac <- bind_rows(psm_ceac, markov_ceac)

# Combined CEAC plot
ggplot(combined_ceac, aes(x = WTP, y = Probability, color = Model, linetype = Model)) +
  geom_line(linewidth = 0.5) +
  labs(
    title = "Cost-effectiveness Acceptability Curve",
    x = "Willingness-to-Pay Threshold (£)",
    y = "Probability of Cost-effectiveness"
  ) +
  scale_x_continuous(
    labels = function(x) paste0("£", format(round(x, 0), big.mark = ",")),
    limits = c(0, max(willingness_to_pay)),
    breaks = seq(0, 200000, 50000)
  ) +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = seq(0, 1, by = 0.1)
  ) +
  scale_color_manual(
    values = c("Partitioned Survival Model" = "#3366cc", "Markov Model" = "#cc3366"),
    name = ""
  ) +
  scale_linetype_manual(
    values = c("Partitioned Survival Model" = "solid", "Markov Model" = "dashed"),
    name = ""
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 10),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray95")
  )

```

## Expected value of perfect information on the individual level

```{r,results='asis', echo=TRUE, message=FALSE, warning=FALSE, fig.height=8, fig.width=12}

# Data frame for EVPI results

# PSM
psm_evpi <- cea_out$evpi %>%
  dplyr::select(k, evpi) %>%
  rename(WTP = k) %>%
  mutate(Model = "Partitioned Survival Model")

# Markov
markov_evpi <- evpi_data %>%
  rename(WTP = wtp) %>%
  mutate(Model = "Markov Model")

# Combine the datasets
combined_evpi <- bind_rows(psm_evpi, markov_evpi)

# Combined EVPI plot
ggplot(combined_evpi, aes(x = WTP, y = evpi, color = Model, linetype = Model)) +
  geom_line(linewidth = 0.5) +
  labs(
    title = "Expected Value of Perfect Information",
    x = "Willingness-to-Pay Threshold (£)",
    y = "EVPI (£)"
  ) +
  scale_x_continuous(
    labels = function(x) paste0("£", format(round(x, 0), big.mark = ",")),
    limits = c(0, max(willingness_to_pay)),
    breaks = seq(0, 200000, 50000)
  ) +
  scale_y_continuous(
    labels = function(x) paste0("£", format(round(x, 0), big.mark = ",", scientific = FALSE)),  
    breaks = scales::pretty_breaks(n = 8)
  ) +
  scale_color_manual(
    values = c("Partitioned Survival Model" = "#3366cc", "Markov Model" = "#cc3366"),
    name = ""
  ) +
  scale_linetype_manual(
    values = c("Partitioned Survival Model" = "solid", "Markov Model" = "dashed"),
    name = ""
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 10),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray95")
  )


```
